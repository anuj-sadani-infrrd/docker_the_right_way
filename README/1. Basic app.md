## Check if docker is installed
`docker version`

## Create a project directory
`mkdir -p Projects/docker101/`

## Create the virtual env for python
`conda create -n d101 python=3.7.16 ipython`

## Create the `app.py`
```
from flask import Flask, request, jsonify
import spacy

# Load the Spacy model
nlp = spacy.load("en_core_web_sm")
print("Spacy model loaded successfully!")

# Define the Flask app
app = Flask(__name__)

# Define a route for text classification prediction
@app.route("/predict", methods=["POST"])
def predict():
    # Get the text input from the request body
    text = request.json["text"]

    # Process the text with Spacy
    doc = nlp(text)

    # Find named entities, phrases and concepts
    orgs = [entity.text for entity in doc.ents if entity.label_ == "ORG"]

    # Return the prediction result as JSON
    return jsonify({"ORGS": orgs})

if __name__ == "__main__":
    app.run(debug=True)
```

## Run python app.py
`python app.py`

> There will be an error as Flask and spacy are not available


## Create requirements.txt
```
Flask==2.2.3
spacy==3.5.2
```

`pip install -r requirements.txt`

## Rerun the app.py
`python app.py`
> OSError: [E050] Can't find model 'en_core_web_sm'

## Dowload the model from spacy
`python -m spacy download en_core_web_sm`

## Run the application
`python app.py`

## Test the application 
```
curl -X POST -H "Content-Type: application/json" -d '{"text":"Infrrd.ai provides best in class solution for IDP"}' http://127.0.0.1:5000/predict
```
